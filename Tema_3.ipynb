{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Día 3: Tipologías de Modelos y Detección de Anomalías en Series Temporales\n",
    "\n",
    "En este notebook cubriremos los siguientes puntos:\n",
    "1. **Generación (o carga) de datos** para trabajar.\n",
    "2. **Resumen de tipologías de modelos**:\n",
    "   - Modelos estadísticos (ARIMA).\n",
    "   - Modelo supervisado simple.\n",
    "   - Modelo no supervisado (Isolation Forest).\n",
    "3. **Detección de anomalías**:\n",
    "   - Método estadístico simple (z-score).\n",
    "   - Isolation Forest.\n",
    "4. **Comparación de resultados**.\n",
    "5. **Tarea** para profundizar.\n",
    "\n",
    "**Objetivo**: Familiarizarnos con distintas categorías de modelos y aprender métodos básicos de detección de anomalías en datos temporales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 0: Importaciones y Configuración\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelos estadísticos\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Para modelo supervisado\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Para detección de anomalías no supervisada\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Para métricas y z-score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Entorno de trabajo configurado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 1: Generación (o Carga) de Datos\n",
    "\n",
    "Para esta práctica, generaremos de forma **sintética** una serie temporal con:\n",
    "- Tendencia creciente.\n",
    "- Estacionalidad mensual (aprox. 30 días).\n",
    "- Ruido aleatorio.\n",
    "- **Anomalías inyectadas** en ciertos puntos, para ilustrar la detección de outliers.\n",
    "\n",
    "Si deseas usar un dataset propio o real, reemplaza la siguiente celda por una lectura de datos, por ejemplo:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"mi_dataset.csv\", parse_dates=[\"fecha\"], index_col=\"fecha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 1: Creación de datos sintéticos con anomalías\n",
    "\n",
    "np.random.seed(42)  # Semilla para reproducibilidad\n",
    "\n",
    "date_range = pd.date_range(start='2025-01-01', end='2025-12-31', freq='D')\n",
    "n = len(date_range)\n",
    "\n",
    "# Tendencia lineal\n",
    "trend = np.linspace(50, 150, n)\n",
    "\n",
    "# Estacionalidad (aprox 30 días)\n",
    "seasonality = 10 * np.sin(2 * np.pi * np.arange(n) / 30)\n",
    "\n",
    "# Ruido normal\n",
    "noise = np.random.normal(loc=0, scale=5, size=n)\n",
    "\n",
    "# Generamos la serie base\n",
    "values = trend + seasonality + noise\n",
    "\n",
    "# Inyectamos algunas anomalías (picos altos o muy bajos)\n",
    "anomaly_indices = np.random.choice(n, size=5, replace=False)  # 5 anomalías al azar\n",
    "values[anomaly_indices] += np.random.choice([30, -30], size=5)  # Añadimos un salto\n",
    "\n",
    "# Creamos DataFrame\n",
    "df = pd.DataFrame({'consumo': values}, index=date_range)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que `df` tiene dos columnas:\n",
    "- **Index**: la fecha.\n",
    "- **consumo**: la serie con tendencia, estacionalidad, ruido y algunos valores anómalos.\n",
    "\n",
    "---\n",
    "## Sección 2: Visualización Inicial\n",
    "\n",
    "Antes de entrar en los modelos, revisamos la serie para ver su apariencia general y, si es posible, detectar \"a simple vista\" las anomalías.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 2: Visualización de la serie\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df.index, df['consumo'], label='Consumo', alpha=0.8)\n",
    "plt.title('Serie Temporal con posibles anomalías')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Consumo')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos suerte, algunas anomalías (puntos muy altos o muy bajos) se verán a simple vista.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección 3: Modelos Estadísticos Clásicos (ARIMA)\n",
    "\n",
    "### 3.1. Breve explicación\n",
    "- **ARIMA(p, d, q)** modela la serie como una combinación de partes autorregresivas (AR), diferencias (I) y medias móviles (MA).\n",
    "- Para este ejemplo, **no** realizaremos un tuning completo de p, d, q. Solo mostraremos cómo ajustar un ARIMA simple con `statsmodels`.\n",
    "\n",
    "### 3.2. Ejemplo: Ajuste ARIMA a nuestra serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 3: Ajuste simple de un modelo ARIMA\n",
    "# Para un ejemplo rápido, seleccionamos manualmente p, d, q:\n",
    "p, d, q = 2, 1, 2\n",
    "\n",
    "# Generamos la serie en un formato un poco más \"clásico\" para ARIMA (simple array)\n",
    "serie = df['consumo']\n",
    "\n",
    "# Ajustamos el modelo\n",
    "model = ARIMA(serie, order=(p, d, q))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación**:\n",
    "- El output de `.summary()` nos da parámetros (AR, MA) y medidas de ajuste (AIC, BIC).\n",
    "- Podríamos intentar diferentes órdenes (p,d,q) o usar funciones como `pmdarima` para auto-ARIMA, pero eso excede el enfoque de esta práctica.\n",
    "\n",
    "### 3.3. Pronóstico con el ARIMA ajustado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pronosticamos algunos días del futuro (ej. 15 días)\n",
    "pred_steps = 15\n",
    "forecast = results.forecast(steps=pred_steps)\n",
    "\n",
    "# Construimos un DataFrame para visualización\n",
    "forecast_index = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=pred_steps, freq='D')\n",
    "forecast_df = pd.DataFrame({'forecast': forecast.values}, index=forecast_index)\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df['consumo'], label='Histórico')\n",
    "plt.plot(forecast_df.index, forecast_df['forecast'], label='Pronóstico ARIMA', color='red')\n",
    "plt.legend()\n",
    "plt.title('Pronóstico con ARIMA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el resultado del modelo ARIMA (muy básico). No esperes una gran precisión si la serie contiene anomalías o si la estacionalidad no se manejó con SARIMA.  \n",
    "Esto ilustra el **modelo estadístico clásico**.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección 4: Modelo Supervisado Sencillo (Regresión Lineal)\n",
    "\n",
    "### 4.1. Idea General\n",
    "- Podemos tratar la predicción de la serie como un problema de **regresión supervisada**.\n",
    "- Generamos features a partir de la propia serie (lags) y quizás alguna variable exógena (en este ejemplo, no la usaremos).\n",
    "\n",
    "### 4.2. Construcción de Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 4: Modelo supervisado sencillo\n",
    "\n",
    "df_supervised = df.copy()\n",
    "\n",
    "# Creamos características: consumo (t-1), consumo (t-2)\n",
    "df_supervised['consumo_lag1'] = df_supervised['consumo'].shift(1)\n",
    "df_supervised['consumo_lag2'] = df_supervised['consumo'].shift(2)\n",
    "\n",
    "# Eliminamos filas iniciales con NaN por shift\n",
    "df_supervised.dropna(inplace=True)\n",
    "\n",
    "# Definimos X e y\n",
    "X = df_supervised[['consumo_lag1', 'consumo_lag2']]\n",
    "y = df_supervised['consumo']\n",
    "\n",
    "# Separamos un conjunto de entrenamiento y test (por ejemplo, 80% para entrenar)\n",
    "split_index = int(len(df_supervised)*0.8)\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "# Entrenamos modelo de regresión lineal\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Coeficientes:\", lr.coef_)\n",
    "print(\"Intercepto:\", lr.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Predicción y visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Armamos DataFrame para graficar\n",
    "df_pred = pd.DataFrame({'real': y_test, 'pred': y_pred}, index=y_test.index)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df_pred.index, df_pred['real'], label='Real', alpha=0.7)\n",
    "plt.plot(df_pred.index, df_pred['pred'], label='Predicción Reg. Lineal', alpha=0.7)\n",
    "plt.title('Predicción con Modelo Supervisado (Reg. Lineal)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentario**:\n",
    "- El modelo se basa únicamente en valores pasados (`lag1`, `lag2`); no tiene en cuenta estacionalidad a largo plazo ni anomalías explícitamente.\n",
    "- Aun así, sirve para ilustrar cómo un **modelo supervisado** puede predecir la serie.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección 5: Detección de Anomalías\n",
    "\n",
    "Ahora que tenemos la serie (con algunos outliers inyectados), veremos dos enfoques:\n",
    "\n",
    "1. **Método estadístico simple (z-score)**.  \n",
    "2. **Isolation Forest** (no supervisado).\n",
    "\n",
    "### 5.1. Método Estadístico (z-score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 5.1: Detección con z-score\n",
    "\n",
    "df_anomalies = df.copy()\n",
    "df_anomalies['z_score'] = zscore(df_anomalies['consumo'])  # scipy.stats.zscore\n",
    "\n",
    "threshold = 3  # más allá de +/-3 se puede considerar outlier\n",
    "df_anomalies['anomaly_z'] = df_anomalies['z_score'].apply(lambda x: 1 if abs(x) > threshold else 0)\n",
    "\n",
    "# Visualizamos cuántos outliers detectamos\n",
    "print(\"Número de anomalías detectadas (z-score):\", df_anomalies['anomaly_z'].sum())\n",
    "\n",
    "# Graficamos la serie, resaltando anomalías\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df_anomalies.index, df_anomalies['consumo'], label='Consumo', alpha=0.7)\n",
    "\n",
    "# Resaltamos en rojo los puntos outliers\n",
    "plt.scatter(df_anomalies.index[df_anomalies['anomaly_z'] == 1],\n",
    "            df_anomalies['consumo'][df_anomalies['anomaly_z'] == 1],\n",
    "            color='red', label='Anomalía (z-score)', alpha=0.9)\n",
    "\n",
    "plt.title('Detección de Anomalías con z-score')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Consumo')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que este método **asume** que la mayoría de los valores se distribuyen de forma aproximadamente normal.  \n",
    "Si en tu serie hay estacionalidad o tendencia fuerte, es útil primero **centrar** la serie (por ejemplo, restarle la media móvil o usar los residuales).\n",
    "\n",
    "### 5.2. Detección con Isolation Forest\n",
    "\n",
    "Un método **no supervisado** que “aísla” puntos anómalos más rápidamente que puntos normales en un bosque de árboles aleatorios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 5.2: Detección con Isolation Forest\n",
    "\n",
    "df_iforest = df.copy()\n",
    "\n",
    "# Configuramos el modelo\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "# Contamination ~ ratio de anomalías esperado (1% en este ejemplo)\n",
    "\n",
    "# Ajustamos y predecimos\n",
    "iso_forest.fit(df_iforest[['consumo']])\n",
    "df_iforest['anomaly_if'] = iso_forest.predict(df_iforest[['consumo']])\n",
    "# Isolation Forest retorna -1 para anómalo, 1 para normal\n",
    "\n",
    "# Convertimos a 1/0\n",
    "df_iforest['anomaly_if'] = df_iforest['anomaly_if'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "print(\"Número de anomalías detectadas (Isolation Forest):\", df_iforest['anomaly_if'].sum())\n",
    "\n",
    "# Visualizamos\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df_iforest.index, df_iforest['consumo'], label='Consumo', alpha=0.7)\n",
    "\n",
    "plt.scatter(df_iforest.index[df_iforest['anomaly_if'] == 1],\n",
    "            df_iforest['consumo'][df_iforest['anomaly_if'] == 1],\n",
    "            color='orange', label='Anomalía (IForest)', alpha=0.9)\n",
    "\n",
    "plt.title('Detección de Anomalías con Isolation Forest')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Consumo')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios**:\n",
    "- Con `contamination=0.01`, forzamos a que ~1% de los datos sean considerados anómalos. Podemos ajustar este hiperparámetro según el dominio del problema.\n",
    "- A diferencia del z-score, Isolation Forest no asume nada sobre la distribución de los datos, pero requiere un volumen razonable de muestras.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección 6: Comparación de Enfoques\n",
    "\n",
    "Podemos comparar cuántas anomalías detecta cada método y si coinciden:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame({\n",
    "    'z_score': df_anomalies['anomaly_z'],\n",
    "    'iforest': df_iforest['anomaly_if']\n",
    "}, index=df.index)\n",
    "\n",
    "df_compare['match'] = (df_compare['z_score'] == df_compare['iforest']).astype(int)\n",
    "\n",
    "print(\"Coincidencias en la etiqueta de anomalía:\", df_compare['match'].sum(), \"de\", len(df_compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiblemente, algunos puntos marcados como anomalía por z-score no lo sean para Isolation Forest, y viceversa. Esto demuestra cómo los **métodos** tienen distintos supuestos y sensibilidades.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección 7: Tarea\n",
    "\n",
    "1. **Probar distintos umbrales** de z-score (por ejemplo, 2.5, 3, 3.5) y ver cómo cambian las detecciones.\n",
    "2. **Ajustar** el parámetro `contamination` de Isolation Forest (por ejemplo, 0.01, 0.02, 0.05) para ver el impacto.\n",
    "3. (Opcional) **Implementar** un método de clustering (por ejemplo, K-Means) en ventanas de la serie para detectar outliers en la serie.\n",
    "4. **Consultar** la documentación de `statsmodels` para un modelo SARIMA que maneje la estacionalidad más adecuadamente.\n",
    "\n",
    "---\n",
    "\n",
    "# Conclusión\n",
    "\n",
    "En este notebook, hemos:\n",
    "- Explorado **tipologías de modelos** (ARIMA, Regresión Lineal, Isolation Forest).\n",
    "- Visto **detección de anomalías** con un método simple (z-score) y uno no supervisado (Isolation Forest).\n",
    "- Aprendido la **importancia** de adaptar los parámetros y el preprocesamiento (estacionalidad, tendencia) antes de marcar puntos como anómalos.\n",
    "\n",
    "¡Con esto concluye la parte práctica del Día 3!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomendaciones finales\n",
    "Ajusta o profundiza según el nivel de la audiencia. Por ejemplo, si quieres enseñar SARIMA con statsmodels, muestra cómo se definen (p, d, q)(P, D, Q)m y cómo buscar los parámetros.\n",
    "Para modelos supervisados más avanzados, podrías integrar RandomForestRegressor o XGBoost, pero lo esencial es entender la idea de “generar features” a partir de la serie.\n",
    "En detección de anomalías, si tu dataset es multivariable, podrías alimentar Isolation Forest con varias columnas (ej. consumo, temperatura, festivo), no solo consumo.\n",
    "Recuerda que la práctica (ensayo y error) es fundamental para ver cómo cambia la detección de anomalías ante diferentes hiperparámetros."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
